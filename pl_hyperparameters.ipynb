{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": true
    },
    "colab": {
      "name": "pl_hyperparameters.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/electrolabopen/pytorch-lightning/blob/main/pl_hyperparameters.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PK1zOjI_LViz"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/sensioai/blog/blob/master/058_pl_metrics_callbacks/pl_metrics_callbacks.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yM1rIG15LVi-"
      },
      "source": [
        "# Pytorch Lightning - Hyperpar√°metros"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTvEQfehLVjA"
      },
      "source": [
        "En posts anteriores hemos estado aprendiendo a utilizar la librer√≠a de `Pytorch Lightning`, que nos ayuda mucho a la hora de entrenar redes neuronales. Tras ver los conceptos fundamentales para empezar a trabajar con esta librer√≠a, y funcionalidad m√°s avanzada como el c√°lculo de m√©tricas y *callbacks*, en este post aprenderemos sobre como podemos manejar los diferentes hyperpar√°metros de nuestro modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9c0I-A0LVjB",
        "outputId": "6af6912d-e42a-4b8b-f63a-6e8d3a94b942"
      },
      "source": [
        "import pytorch_lightning as pl\n",
        "\n",
        "pl.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.0.7'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVZDHxMBLVjE"
      },
      "source": [
        "> üí° Puedes instalar pythorch lighning con el comando `pip install pytorch-lightning`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbE5EiUSLVjF"
      },
      "source": [
        "Por defecto, cualquier variable que le pasemos a nuestro *LightningModule* en la funci√≥n `__init__` ser√° considerado como un hyperpar√°metro. `Pytorch Lightning` guardar√° estas variables en el objeto `self.hparams`, que podremos utilizar en cualquier lugar, siempre y cuando llamemos a la funci√≥n `self.save_hyperparameters`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3TgUBZnLVjF"
      },
      "source": [
        "import torch \n",
        "import torchvision\n",
        "\n",
        "class MNISTDataModule(pl.LightningDataModule):\n",
        "\n",
        "    def __init__(self, path = '../data', batch_size = 64):\n",
        "        super().__init__()\n",
        "        self.path = path\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def setup(self, stage=None):\n",
        "        self.mnist_train = torchvision.datasets.MNIST(\n",
        "            self.path, train=True, download=True, transform=torchvision.transforms.Compose([\n",
        "                torchvision.transforms.ToTensor(),\n",
        "                torchvision.transforms.Normalize((0.1307,), (0.3081,))\n",
        "                ])\n",
        "          )\n",
        "        self.mnist_val = torchvision.datasets.MNIST(\n",
        "            self.path, train=False, download=True, transform=torchvision.transforms.Compose([\n",
        "                torchvision.transforms.ToTensor(),\n",
        "                torchvision.transforms.Normalize((0.1307,), (0.3081,))\n",
        "                ])\n",
        "          )\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return torch.utils.data.DataLoader(self.mnist_train, batch_size=self.batch_size, shuffle=True)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return torch.utils.data.DataLoader(self.mnist_val, batch_size=self.batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVTGPBW6LVjH"
      },
      "source": [
        "from pytorch_lightning.metrics.functional.classification import accuracy\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def block(c_in, c_out, k=3, p=1, s=1, pk=2, ps=2):\n",
        "    return torch.nn.Sequential(\n",
        "        torch.nn.Conv2d(c_in, c_out, k, padding=p, stride=s),\n",
        "        torch.nn.ReLU(),\n",
        "        torch.nn.MaxPool2d(pk, stride=ps)\n",
        "    )\n",
        "\n",
        "class Modelo(pl.LightningModule):\n",
        "    \n",
        "    def __init__(self, n_channels=1, n_outputs=10):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()\n",
        "        self.conv1 = block(self.hparams.n_channels, 64)\n",
        "        self.conv2 = block(64, 128)\n",
        "        self.fc = torch.nn.Linear(128*7*7, self.hparams.n_outputs)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = x.view(x.shape[0], -1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        y_hat = self(x)\n",
        "        loss = F.cross_entropy(y_hat, y)\n",
        "        self.log('loss', loss)\n",
        "        self.log('acc', accuracy(y_hat, y), prog_bar=True)\n",
        "        return loss\n",
        "    \n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        y_hat = self(x)\n",
        "        loss = F.cross_entropy(y_hat, y)\n",
        "        self.log('val_loss', loss, prog_bar=True)\n",
        "        self.log('val_acc', accuracy(y_hat, y), prog_bar=True)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.Adam(self.parameters(), lr=1e-3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PbSn7PYCLVjI",
        "outputId": "73ab5ab5-0c5b-47f8-f4aa-4320d12c197f"
      },
      "source": [
        "model = Modelo()\n",
        "\n",
        "model.hparams"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"n_channels\": 1\n",
              "\"n_outputs\":  10"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Ex72qqMLVjJ"
      },
      "source": [
        "Si bien podemos trabajar de esta manera, la cosa se complicar√° cuando tengamos muchos hyperpar√°metros. Adem√°s, existen otros que tambi√©n es importante guardar pero que no le pasaremos al modelo, como por ejemplo el *batch size*. Para solventar este problema, es com√∫n definir todos los hyperpar√°metros en un solo `dict`, que pasaremos al nuestro modelo y guardaremos en la misma funci√≥n usada anteriormente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wncJgFtRLVjJ"
      },
      "source": [
        "class Modelo(pl.LightningModule):\n",
        "    \n",
        "    def __init__(self, config, n_channels = 1, n_outputs = 10):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters(config)\n",
        "        self.conv1 = block(n_channels, self.hparams.filters1)\n",
        "        self.conv2 = block(self.hparams.filters1, self.hparams.filters2)\n",
        "        self.fc = torch.nn.Linear(self.hparams.filters2*7*7, n_outputs)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = x.view(x.shape[0], -1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        y_hat = self(x)\n",
        "        loss = F.cross_entropy(y_hat, y)\n",
        "        self.log('loss', loss)\n",
        "        self.log('acc', accuracy(y_hat, y), prog_bar=True)\n",
        "        return loss\n",
        "    \n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        y_hat = self(x)\n",
        "        loss = F.cross_entropy(y_hat, y)\n",
        "        self.log('val_loss', loss, prog_bar=True)\n",
        "        self.log('val_acc', accuracy(y_hat, y), prog_bar=True)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return getattr(torch.optim, self.hparams.optimizer)(self.parameters(), lr=self.hparams.lr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v22IJzcCLVjL",
        "colab": {
          "referenced_widgets": [
            "",
            "bbc5c9e928514016af629cf4e60df250"
          ]
        },
        "outputId": "40408f44-6d4a-4c6e-bc47-21fe161b5186"
      },
      "source": [
        "config = {\n",
        "    'lr': 3e-4, \n",
        "    'optimizer': 'Adam',\n",
        "    'batch_size': 64,\n",
        "    'filters1': 32, \n",
        "    'filters2': 64\n",
        "}\n",
        "\n",
        "modelo = Modelo(config)\n",
        "dm = MNISTDataModule(batch_size=config['batch_size'])\n",
        "\n",
        "trainer = pl.Trainer(max_epochs=5, gpus=1)\n",
        "trainer.fit(modelo, dm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name  | Type       | Params\n",
            "-------------------------------------\n",
            "0 | conv1 | Sequential | 640   \n",
            "1 | conv2 | Sequential | 73 K  \n",
            "2 | fc    | Linear     | 62 K  \n",
            "/home/sensio/miniconda3/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:45: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 20 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
            "  warnings.warn(*args, **kwargs)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout‚Ä¶"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/home/sensio/miniconda3/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:45: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 20 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
            "  warnings.warn(*args, **kwargs)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bbc5c9e928514016af629cf4e60df250",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max‚Ä¶"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m‚Ä¶"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m‚Ä¶"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m‚Ä¶"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m‚Ä¶"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m‚Ä¶"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_358GCnLVjM",
        "outputId": "d969b10b-8ba7-4311-9abd-4dd74ea97a92"
      },
      "source": [
        "modelo.hparams "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"batch_size\": 64\n",
              "\"filters1\":   32\n",
              "\"filters2\":   64\n",
              "\"lr\":         0.0003\n",
              "\"optimizer\":  Adam"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FBiI4xfLVjM"
      },
      "source": [
        "Podemos acceder a estos hyperpar√°metros incluso despu√©s de cargar un modelo a partir de un *checkpoint*. De esta manera, siempre sabremos el conjunto de par√°metros utilizados para entrenar nuestro modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFpl4O-yLVjN",
        "colab": {
          "referenced_widgets": [
            "",
            "25dfd810362c4277a2359e953805e221"
          ]
        },
        "outputId": "00c06665-03d1-4526-d25b-e5a32cf45f62"
      },
      "source": [
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
        "\n",
        "config = {\n",
        "    'lr': 3e-4, \n",
        "    'optimizer': 'Adam',\n",
        "    'batch_size': 64,\n",
        "    'filters1': 32, \n",
        "    'filters2': 64\n",
        "}\n",
        "\n",
        "modelo = Modelo(config)\n",
        "dm = MNISTDataModule(batch_size=config['batch_size'])\n",
        "\n",
        "# callbacks \n",
        "\n",
        "early_stop_callback = EarlyStopping(\n",
        "   monitor='val_acc',\n",
        "   patience=3,\n",
        "   verbose=False,\n",
        "   mode='max'\n",
        ")\n",
        "\n",
        "checkpoint = ModelCheckpoint(\n",
        "    dirpath='./', \n",
        "    filename='modelo-{val_acc:.5f}', \n",
        "    save_top_k=1,\n",
        "    monitor='val_acc', \n",
        "    mode='max'\n",
        ")\n",
        "\n",
        "# entrenamiento\n",
        "\n",
        "trainer = pl.Trainer(\n",
        "    gpus=1,\n",
        "    callbacks=[\n",
        "        early_stop_callback,\n",
        "        checkpoint\n",
        "    ]\n",
        ")\n",
        "\n",
        "trainer.fit(modelo, dm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/home/sensio/miniconda3/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:45: UserWarning: Checkpoint directory ./ exists and is not empty. With save_top_k=1, all files in this directory will be deleted when a checkpoint is saved!\n",
            "  warnings.warn(*args, **kwargs)\n",
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name  | Type       | Params\n",
            "-------------------------------------\n",
            "0 | conv1 | Sequential | 640   \n",
            "1 | conv2 | Sequential | 73 K  \n",
            "2 | fc    | Linear     | 62 K  \n",
            "/home/sensio/miniconda3/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:45: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 20 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
            "  warnings.warn(*args, **kwargs)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout‚Ä¶"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/home/sensio/miniconda3/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:45: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 20 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
            "  warnings.warn(*args, **kwargs)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "25dfd810362c4277a2359e953805e221",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max‚Ä¶"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m‚Ä¶"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m‚Ä¶"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m‚Ä¶"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m‚Ä¶"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m‚Ä¶"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m‚Ä¶"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m‚Ä¶"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m‚Ä¶"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m‚Ä¶"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m‚Ä¶"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tG6RPn0eLVjP",
        "outputId": "f532723b-71a0-42e6-c45e-73a1d9c9cdd4"
      },
      "source": [
        "modelo = Modelo.load_from_checkpoint(checkpoint_path=\"modelo-val_acc=0.99120.ckpt\")\n",
        "modelo.hparams"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"batch_size\": 64\n",
              "\"filters1\":   32\n",
              "\"filters2\":   64\n",
              "\"lr\":         0.0003\n",
              "\"optimizer\":  Adam"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSUyq9uoLVjR"
      },
      "source": [
        "Por √∫ltimo, `Pytorch Lightning` tambi√©n ofrece una manera de interactuar con estos hyperpar√°metros iterpretando los argumentos pasados al ejectura un *script*. Puedes aprender m√°s al respecto [aqu√≠](https://pytorch-lightning.readthedocs.io/en/stable/hyperparameters.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZQ63O-tLVjR"
      },
      "source": [
        "## Resumen"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgYxQpzGLVjS"
      },
      "source": [
        "En este post hemos visto c√≥mo podemos manejar los diferentes hyperpar√°metros utilizados para entrenar nuestros modelos: el *learning rate*, *batch size*, el optimizador usado, el n√∫mero de capas convolucionales o filtros... Todos estos par√°metros influyen en el resultado obtenido, y es importante guardar todos estos valores junto al modelo para no repetir trabajo o poder comparar modelos entre s√≠ o con otros. Definiendo un `dict` con todos los hyperpar√°metros, lo pasaremos al modelo en su inicializaci√≥n y simplemente llamando a la funci√≥n `self.save_hyperparameters`, `Pytorch Lightning` se encargar√° de guardar estos valores, hacerlos accesibles a trav√©s del objeto `self.hparams` y guardarlos y cargarlos en los *checkpoints*."
      ]
    }
  ]
}